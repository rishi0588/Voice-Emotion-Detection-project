# ğŸ™ï¸ Voice Emotion Detection using Deep Learning

## ğŸ§  Overview
This project detects **human emotions from voice recordings** using **audio signal processing** and a **deep learning model** built with TensorFlow and Keras.  
It features a **Streamlit web app** that lets users upload or record voice samples, visualize waveforms, view emotion confidence scores, and download reports in **CSV** and **PDF** format.

---

## ğŸš€ Features
âœ… Upload or record audio using a built-in microphone interface  
âœ… Automatic waveform visualization  
âœ… Real-time **emotion classification** (Angry, Happy, Calm, Sad, Fearful, Neutral, etc.)  
âœ… Speech transcription using **Google SpeechRecognition API**  
âœ… Confidence-based emotion probability chart  
âœ… Exportable **PDF and CSV reports**  
âœ… Lightweight, intuitive **Streamlit** interface  

---

## ğŸ§© Tech Stack

| Component | Technology / Library |
|------------|----------------------|
| **Frontend UI** | Streamlit |
| **Audio Processing** | Librosa, PyDub, FFmpeg |
| **Model Training** | TensorFlow / Keras |
| **Feature Extraction** | MFCCs, Mel Spectrogram, Spectral Contrast |
| **Speech Transcription** | SpeechRecognition (Google Web API) |
| **Reporting** | Pandas, FPDF |
| **Language/NLP Connection** | Speech-to-text and semantic understanding |

---

## ğŸ§° Installation

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/rishi0588/Voice-Emotion-Detection-project.git
cd voice-emotion-detection
2ï¸âƒ£ Install Dependencies
bash
Copy code
pip install -r requirements.txt
3ï¸âƒ£ Install FFmpeg (Required for PyDub)
bash
Copy code
python -m ffmpeg_downloader install
4ï¸âƒ£ Run the App
bash
Copy code
streamlit run app.py
ğŸ§  How It Works
Audio Input â€” User either uploads a .wav file or records audio via Streamlitâ€™s microphone.

Feature Extraction â€” feature_extraction.py extracts MFCCs, Mel Spectrograms, and Spectral Contrast features using Librosa.

Emotion Classification â€” The features are passed into a feed-forward neural network trained on emotional speech data (e.g. RAVDESS or custom dataset).

Confidence Estimation â€” The model outputs class probabilities; temperature scaling is applied to reduce bias.

Speech Recognition â€” Audio is transcribed into text using Google SpeechRecognition API.

Visualization & Reports â€” Streamlit displays the waveform, emotion chart, and transcript, and generates downloadable PDF + CSV reports.

ğŸ§ª Model Details
Architecture: 3-layer Dense neural network with ReLU activations and Dropout regularization.

Trained using: RAVDESS dataset or similar emotional speech data.

Input Features: 200-dimensional vector of MFCC, Mel, and Spectral Contrast features.

Output Labels: 8 emotion classes â€” ['angry', 'calm', 'disgust', 'fearful', 'happy', 'neutral', 'sad', 'surprised'].

Loss: Categorical Cross-Entropy

Optimizer: Adam

ğŸ“Š Output Example
Detected Emotion: Happy ğŸ˜„

Confidence Scores:

Emotion	Confidence
Happy	0.72
Calm	0.15
Neutral	0.09
Angry	0.04

Transcription: â€œHello, Iâ€™m Rishi and Iâ€™m very happy today!â€

Duration: 3.5 seconds

Generated Files:

emotion_report.csv

emotion_report.pdf

ğŸ§­ NLP Connection
Although primarily audio-based, this project integrates NLP concepts through speech transcription.
The recognized text can be used for:

Sentiment analysis,

Semantic context understanding,

Multimodal emotion recognition (voice + text).

Thus, it bridges speech signal processing and Natural Language Processing (NLP) for richer emotional insight.

ğŸ Future Enhancements
ğŸ”¹ Use Transformer models (e.g., Wav2Vec2 or Whisper) for direct end-to-end speech emotion recognition.

ğŸ”¹ Combine voice tone + text sentiment for multi-modal emotion analysis.

ğŸ”¹ Add timeline emotion visualization across longer recordings.

ğŸ”¹ Optimize for Indian regional languages.

ğŸ§‘â€ğŸ’» Author
Rishi Ponda
Shivansh Khandelwal
Priyanshu P/adhi
ğŸ“ MBA (Tech) â€” Data Science, MPSTME NMIMS

ğŸªª License
This project is open source and available under the MIT License.

â­ If you found this project useful, consider giving it a star on GitHub! â­
